import os
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_PROMPT = """
Ivair, voc√™ √© o representante comercial da 100fronteiras ‚Äî portal de comunica√ß√£o e eventos culturais da regi√£o da Tr√≠plice Fronteira. Sua miss√£o √© prospectar e converter clientes corporativos que desejam aumentar sua visibilidade na regi√£o atrav√©s de parcerias editoriais e patroc√≠nios.

Atua como consultor comercial especializado em comunica√ß√£o digital, eventos culturais (como o 100fronteiras JAZZ Festival) e conte√∫do editorial para empresas que buscam impacto regional.

Voc√™ NUNCA soa rob√≥tico. Comunica√ß√£o natural, direta e profissional. Fala como especialista em comunica√ß√£o regional que entende as necessidades locais.

**SEUS DIFERENCIAIS:**
- Portal consolidado na Tr√≠plice Fronteira com audi√™ncia fiel
- Expertise em eventos culturais (JAZZ Festival, outros)
- Relacionamento com √≥rg√£os p√∫blicos e empresas regionais  
- Produ√ß√£o editorial especializada em turismo, cultura e neg√≥cios locais
- M√©tricas de alcance e engajamento comprovadas

‚ö†Ô∏è **LIMITADOR**: M√°ximo **60 tokens** por resposta.

üéØ **OBJETIVO**: Converter prospects em parceiros comerciais da 100fronteiras com naturalidade e expertise regional.

üß† **DADOS CONHECIDOS:**
- Portal ativo h√° anos na regi√£o da Tr√≠plice Fronteira
- Cobertura editorial: turismo, cultura, eventos, neg√≥cios locais
- Eventos pr√≥prios: 100fronteiras JAZZ Festival (4¬™ edi√ß√£o)
- Parcerias institucionais: prefeituras, Itaipu, Sanepar, √≥rg√£os estaduais
- Produtos: mat√©rias patrocinadas, cobertura de eventos, revista, parcerias em eventos

üí¨ **TOM**: Profissional experiente, conhecedor da regi√£o, direto nas propostas, focado em resultados mensur√°veis.

Sempre adapte ao perfil do cliente. Construa relacionamento com expertise ‚Äî nunca force venda.

##**MENSAGEM INICIAL:**
"Ol√°, √≥tima semana! Aqui √© [seu nome] da 100fronteiras, com quem falo a√≠ na empresa? Estamos preparando a edi√ß√£o comemorativa de novo formato pelos 20 anos da Revista 100fronteiras e pensei em voc√™s pelo legado que voc√™s constroem."

üîÑ Conduza com conhecimento regional e dados concretos de audi√™ncia.
"""

PROMPT_TEMPLATES = {
    'A': [
        "Boa tarde!",
        "Aqui √© o Ivair, do portal 100fronteiras üëã",
        "A Revista 100fronteiras completa 20 anos em 2026 e estamos montando parcerias estrat√©gicas pra essa edi√ß√£o comemorativa.",
        "Voc√™s j√° fecharam o planejamento de marketing pro ano que vem? Queria trocar uma ideia com voc√™s!"
    ],
    'B': [
        "Ol√°, √≥tima semana!",
        "Aqui √© o Ivair, da 100fronteiras. Com quem eu falo a√≠ no comercial?",
        "Em 2026 a gente comemora 20 anos de portal e revista e estamos buscando marcas que s√£o refer√™ncia na regi√£o.",
        "Lembrei de voc√™s! Posso explicar como podemos trabalhar juntos?"
    ],
    'C': [
        "E a√≠, tudo bem?",
        "Sou o Ivair do 100fronteiras, portal de turismo e cultura da Tr√≠plice Fronteira.",
        "Estamos preparando uma edi√ß√£o especial pelos 20 anos da revista e queremos convidar empresas parceiras pra fazer parte.",
        "Voc√™s teriam interesse em conhecer a proposta? ü§ù"
    ],
    'A_ES': [
        "¬°Buenas tardes!",
        "Soy Ivair, del portal 100fronteiras üëã",
        "La Revista 100fronteiras cumple 20 a√±os en 2026 y estamos armando alianzas estrat√©gicas para esa edici√≥n conmemorativa.",
        "¬øYa cerraron la planificaci√≥n de marketing para el pr√≥ximo a√±o? ¬°Me gustar√≠a conversar con ustedes!"
    ],
    'B_ES': [
        "¬°Hola, excelente semana!",
        "Soy Ivair, de 100fronteiras. ¬øCon qui√©n hablo del √°rea comercial?",
        "En 2026 celebramos 20 a√±os del portal y revista. Buscamos marcas que son referentes en la regi√≥n.",
        "¬°Me acord√© de ustedes! ¬øPuedo explicarles c√≥mo podemos trabajar juntos?"
    ],
    'C_ES': [
        "¬øQu√© tal, todo bien?",
        "Soy Ivair de 100fronteiras, portal de turismo y cultura de la Triple Frontera.",
        "Estamos preparando una edici√≥n especial por los 20 a√±os de la revista y queremos invitar empresas socias a participar.",
        "¬øLes interesar√≠a conocer la propuesta? ü§ù"
    ]
}


def generate_message(lead_data, website_content=None, version='A'):
    
    # Language Detection/Selection
    language = lead_data.get('language', 'pt')
    
    # Adjust version for language
    final_version = version
    if language == 'es' and not version.endswith('_ES'):
        final_version = f"{version}_ES"
        
    # Check if template exists, fallback to A or A_ES
    template = PROMPT_TEMPLATES.get(final_version)
    if not template:
        # Fallback logic
        if language == 'es':
             template = PROMPT_TEMPLATES['A_ES']
        else:
             template = PROMPT_TEMPLATES['A']
    
    context_info = ""
    if website_content:
        context_info = f"\n    CONTE√öDO DO SITE DO CLIENTE (Apenas para contexto, mas tente seguir fielmente o template escolhido):\n    {website_content[:1000]}..."

    user_prompt = f"""
    Siga ESTRITAMENTE o modelo abaixo para gerar a mensagem. Apenas substitua os placeholders entre chaves ou colchetes ([Nome], [Empresa]) pelos dados reais do lead. 
    Se n√£o tiver o nome da pessoa, adapte ligeiramente para n√£o ficar estranho (ex: "Ol√° equipe da [Empresa]").
    
    DADOS DO LEAD:
    Nome: {lead_data.get('name')}
    Empresa: {lead_data.get('name')} (Use este nome para empresa)
    Idioma: {language}
    
    MODELO OBRIGAT√ìRIO (Vers√£o {final_version}):
    ---
    {template}
    ---
    
    INSTRU√á√ÉO CR√çTICA DE FORMATA√á√ÉO:
    Divida a mensagem em 3 ou 4 partes curtas e naturais (como bal√µes de chat), separadas EXATAMENTE por "|||". 
    N√ÉO coloque "Parte 1" ou n√∫meros. Apenas o texto separado por |||.
    
    Exemplo:
    Ol√° [Nome], tudo bem?|||Aqui √© o Ivair...|||Vi que voc√™s...
    
    Gere apenas a mensagem final, sem aspas. Mantenha o idioma do modelo ({language}).
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=300, # Increased for multiple bubbles
            temperature=0.3
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error generating message: {e}")
        return None

def generate_followup_message(lead_data, stage):
    instructions = {
        1: "O cliente n√£o respondeu ao primeiro contato feito h√° 3 dias. Gere uma mensagem curta e educada perguntando se ele conseguiu ver a mensagem anterior. Mantenha o tom profissional e amig√°vel de Ivair.",
        2: "O cliente n√£o respondeu h√° uma semana. Gere uma mensagem trazendo uma novidade ou um benef√≠cio espec√≠fico da 100fronteiras (ex: audi√™ncia qualificada, networking). Algo para despertar interesse.",
        3: "√öltima tentativa. O cliente n√£o responde h√° duas semanas. Gere uma mensagem de 'break-up' suave, dizendo que n√£o vai mais incomodar, mas deixando as portas abertas para o futuro."
    }
    
    instruction = instructions.get(stage, "Gere uma mensagem de follow-up.")
    
    user_prompt = f"""
    Ol√° Ivair, preciso de um follow-up para este cliente:
    Nome: {lead_data.get('name')}
    
    Hist√≥rico da conversa:
    {lead_data.get('conversation_history', '')}
    
    Instru√ß√£o: {instruction}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=100,
            temperature=0.4
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Error generating follow-up: {e}")
        return None


def generate_contextual_message(lead_data, conversation_history):
    """
    Generate a contextual message based on previous Chatwoot conversation history.
    Used when re-engaging with a contact that has prior interactions.
    """
    language = lead_data.get('language', 'pt')
    
    user_prompt = f"""
    Voc√™ precisa gerar uma mensagem de retomada de conversa para este lead.
    
    DADOS DO LEAD:
    Nome: {lead_data.get('name')}
    Empresa: {lead_data.get('name')}
    Idioma: {language}
    
    HIST√ìRICO DA CONVERSA ANTERIOR (Chatwoot):
    {conversation_history}
    
    INSTRU√á√ïES:
    1. Leia o hist√≥rico acima e entenda o contexto da conversa anterior
    2. Gere uma mensagem natural que retome a conversa de forma contextualizada
    3. N√£o repita informa√ß√µes j√° ditas, mas fa√ßa refer√™ncia ao que foi conversado
    4. Mantenha o tom profissional e amig√°vel do Ivair
    5. Foque em avan√ßar a conversa sobre a parceria com a 100fronteiras
    6. A mensagem deve ser dividida em 4 partes curtas (para envio sequencial)
    7. Retorne APENAS as 4 partes separadas por "|||"
    
    Exemplo de formato de resposta:
    Oi [Nome], tudo bem?|||Retomando nossa conversa sobre [assunto]...|||[Continua√ß√£o contextual]|||[Pergunta ou call-to-action]
    
    Gere as 4 partes agora:
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=250,
            temperature=0.5
        )
        
        # Parse response into 4 parts
        message = response.choices[0].message.content.strip()
        parts = [p.strip() for p in message.split('|||')]
        
        # Ensure we have exactly 4 parts
        if len(parts) < 4:
            parts.extend([""] * (4 - len(parts)))
        
        return parts[:4]  # Return only first 4 parts
    except Exception as e:
        print(f"Error generating contextual message: {e}")
        return None

def analyze_conversation_for_name(history_text):
    """
    Analyzes the conversation history to identify the Lead's Name or Company Name.
    Returns JSON: {"name": "Found Name", "confidence": "high/medium/low"}
    """
    if not history_text or len(history_text) < 50:
        return None

    user_prompt = f"""
    Analise o hist√≥rico de conversa abaixo e tente identificar o NOME DA PESSOA ou NOME DA EMPRESA com quem o Ivair est√° falando.
    
    HIST√ìRICO:
    {history_text}
    
    Regras:
    1. Se o cliente se apresentou (ex: "Aqui √© o Jo√£o"), use "Jo√£o".
    2. Se for uma empresa (ex: "Somos da Arquitetura X"), use "Arquitetura X".
    3. Se n√£o tiver certeza, retorne null.
    
    Retorne APENAS um JSON v√°lido:
    {{
        "name": "Nome Encontrado ou null",
        "type": "person/company",
        "confidence": "high/low"
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "Voc√™ √© um assistente que extrai dados de CRM."},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=100,
            temperature=0.1,
            response_format={"type": "json_object"}
        )
        
        import json
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"Error analyzing name: {e}")
        return None
